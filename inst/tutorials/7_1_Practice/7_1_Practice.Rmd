---
title: "Chapter 7"
subtitle: "Regression with Qualitative Information"
description: "This tutorial introduces binary regressors (dummy variables)."
author: 
  name: "Created by [Jim Bang](http://www.github.com/bangecon)"
  email: BangJamesT@sau.edu
  affiliation: "[St. Ambrose University](http://www.sau.edu)"
date: "`r format(Sys.Date(), '%d %b %Y')`"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
always_allow_html: yes
editor_options: 
  markdown: 
    wrap: 72
---

<style type="text/css">
h1{font-size: 24pt}
h2{font-size: 20pt}
h3{font-size: 18pt}
h4,h5,h6{font-size: 16pt}
body{font-size: 16pt}
</style>

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
tutorial_options(exercise.eval = TRUE, exercise.reveal_solution = TRUE)
gradethis::gradethis_setup()
knitr::opts_chunk$set(echo = FALSE)
```

## College GPAs

Estimate the following models using the `gpa2` dataset: 

$$\begin{align}College\text{ }GPA ={} &\beta_0 + \beta_1Athlete + \beta_2Female + \beta_3HS\text{ }Size + \beta_4HS\text{ }Size^2 + \beta_5HS\text{ }Percentile + \beta_6SAT + \\ & \beta_7Nonwhite \text{ : (gpa.lm1)} \end{align}$$ 

$$\begin{align}College\text{ }GPA ={} &\beta_0 + \beta_1Athlete + \beta_2Female + \beta_3HS\text{ }Size + \beta_4HS\text{ }Size^2 + \beta_5HS\text{ }Percentile + \beta_6SAT + \\ & \beta_7Nonwhite + \beta_1Athlete \times Female \text{ : (gpa.lm1)} \end{align}$$

$$\begin{align}College\text{ }GPA ={} &\beta_0 + \beta_1Athlete + \beta_2Female + \beta_3HS\text{ }Size + \beta_4HS\text{ }Size^2 + \beta_5HS\text{ }Percentile + \beta_6SAT + \\ & \beta_7Nonwhite + \beta_1Athlete \times HS\text{ }Percentile \text{ : (gpa.lm1)} \end{align}$$ 

Present your results side-by-side using $stargazer()$. 

```{r athleteGPAs, exercise=TRUE, exercise.reveal_solution = TRUE}

```

```{r athleteGPAs-solution}
library(stargazer)
gpa2 <- wooldridge::gpa2
colgpa.lm1 <- lm(colgpa ~ athlete + female + I(1-white) + hsize + I(hsize^2) + hsperc + sat, data = gpa2)
colgpa.lm2 <- lm(colgpa ~ athlete + female + I(athlete*female) + I(1-white) 
                 + hsize + I(hsize^2) + hsperc + sat, data = gpa2)
colgpa.lm3 <- lm(colgpa ~ athlete + female + I(athlete*scale(hsperc, scale = FALSE)) 
                 + I(1-white) + hsize + I(hsize^2) + hsperc + sat, data = gpa2)
stargazer(colgpa.lm1, colgpa.lm2, colgpa.lm3, type = 'text')
```

```{r athleteGPAs-hint}
# Don't forget to use the I() operator in the terms that require math operations.
# Don't forget to scale continuous interactions. 
```

```{r athleteGPAs-check}
grade_this({
  if (identical(.result, .solution)) {
    pass(random_praise())
  }
  fail(random_encouragement())
})
```

## Demand for Eco-Friendly Apples

Estimate the following model using the `apple` dataset: 

$$\begin{align} 
BuyEcoFreindly = \beta_0 + &\beta_1Price_{Eco} + \beta_2Price_{Reg} + \beta_3Income + \\ 
&\beta_4HHSize + \beta_5Education + \beta_6Age + u 
\end{align}$$ 

Summarize this estimation using the `summary()` function. Summarize the predicted (fitted) values

```{r apple, exercise=TRUE, exercise.reveal_solution = TRUE}

```

```{r apple-solution}
apple <- wooldridge::apple
apple.lm1 <- lm((ecolbs > 0) ~ ecoprc + regprc + faminc + hhsize + educ + age,
                data = apple)
summary(apple.lm1$fitted.values)
```

```{r apple-hint}
# Note that you can create a dummy variable for values greater, less than, or equal to a threshold value using the <, >, and = operators within parentheses. You do not need the I() function, just parentheses. 
```

```{r apple-check}
grade_this({
  if (identical(.result, .solution)) {
    pass(random_praise())
  }
  fail(random_encouragement())
})
```

Interpret the coefficient on the price of eco-friendly apples and the coefficient on regular apples. 
