---
title: "Chapter 11" 
subtitle: "Furher Issues in OLS with Time Series Data"
description: >
  This tutorial introduces some additional problems specific to time series in regression analysis.
author: 
  name: "Created by [Jim Bang](http://www.github.com/bangecon)"
  email: BangJamesT@sau.edu
  affiliation: "[St. Ambrose University](http://www.sau.edu)"
date: "`r format(Sys.Date(), '%d %b %Y')`"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
always_allow_html: yes
editor_options: 
  markdown: 
    wrap: 72
---

<style type="text/css">
h1{font-size: 24pt}
h2{font-size: 20pt}
h3{font-size: 18pt}
h4,h5,h6{font-size: 16pt}
body{font-size: 16pt}
</style>

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
tutorial_options(exercise.eval = TRUE, exercise.reveal_solution = TRUE)
gradethis::gradethis_setup()
knitr::opts_chunk$set(echo = FALSE, fig.height= 9, fig.width=8)
```

## Classical Assumptions

Assumptions needed for $\hat\beta_OLS$ to be "BLUE"

1.  Linear in the parameters  
2.  $X_i$'s and $Y_i$'s are independently and identically distributed
    (random sampling)  
3.  No perfect multicollinearity  
4.  $E(u|X)=0$ (strict exogeneity)  
    a.  No omitted variables  
    b.  No endogenous regressors  
    c.  No measurement error  
    d.  No included "colliders" (e.g. post-treatment effects)  
5.  $Var(u) = \sigma^2$ (homoskedasticity)  
6.  $E(X^4) < 0$, $E(Y^4) < 0$ (no extreme "outliers")  
Additional assumption for $\hat\beta_{OLS}$ to be "MVUE"  
7.  $u \sim N(0, \sigma^2)$ (normal distribution of errors)  

## Strong Assumptions for Time Series (Chapter 10)

Strict independence (2), exogeneity (4), and homoskedasticity (5) may be
unrealistic. Replace with:  
1.  Linear in the parameters  
2.  Independence (random sampling)  
3.  No perfect multicollinearity  
4.  $E(u_t|X)=0$ (strict exogeneity)  
5.  $Var(u) = \sigma^2$ (homoskedasticity)  
6.  $Corr(u_s, u_t |X) = 0, t \neq 0$ (no serial correlation)  

## Weakened Assumptions for Time Series (Chapter 11)

Independence (2), *strict* exogeneity (4), homoskedasticity (5), and *no* serial correlation (6) may be unrealistic. Replace with:  
2. Weak dependence  
    $\lim_{h \to \infty} \text{corr}(X_t, X_{t+h}) = 0$  
    $\lim_{h \to \infty} \text{corr}(Y_t, Y_{t+h}) = 0$  
    Dependence between two values of X and Y decays the farther apart they are.  
Stationarity (three types)  
4.  Mean stationary: $E(x_t) = \mu$ <br> $E(u_t|X_t)=0$ (*contemporaneous* exogeneity)  
5.  Variance stationary: mean stationarity *and* $V(x_t) = \sigma^2$ (*contemporaneous* homoskedasticity)  
6.  Covariance stationary: variance stationarity *and*  
    $Cov(x_t, x_{t+h}) = f(h)$ <br> $E(u_tu_s|X_t,X_s)=0$ (no [contemporaneous?] serial correlation)  

Linearity, weak dependence, no perfect multicollinearity, and
stationarity imply OLS will be *consistent* (but not necessarily
completely unbiased).  

Consistency: $\text{plim}_{t \to \infty}\hat\beta = \beta$

## Examples

Weak Dependence  
1.  MA(1) processes <br> $x_t = e_t + \alpha x_{t-1}$  
2.  AR(1) processes <br> $y_t = \rho y_{t-1} + e_t$  
Non-Stationarity  
1.  Time trend <br> $y_t = \beta t + e_t$  
2.  Seasonality <br> $y_t = \sum_{k=1}^K \delta_k s_kt + e_t$  
3.  Random Walk <br> $y_t = y_{t-1} + e_t$  

Sometimes we can "see" non-stationarity in the time series plot:

```{r}
fertil3 <- wooldridge::fertil3
par(mfrow=c(1,2))
plot(fertil3$year[-1], fertil3$gfr[-1], type = 'l', xlab = "Year", ylab = "Fertility")
plot(fertil3$year[-1], diff(fertil3$gfr), type = 'l', xlab = "Year", ylab = "Change in Fertility")
```

## Exercise

### Setup  

Using the `nyse` dataset and the `dynlm` package, do the following:

1.  Define time series (numbered 1,...,n and named $nyse.ts$)
2.  Line plot the price against the time period
3.  Plot the *return* (change in price) against time period

```{r stationary, exercise = TRUE}


```

```{r stationary-hint}
data.ts <- ts(data)
plot(x, y)
```

```{r stationary-solution}
nyse.ts <- ts(nyse)
plot(nyse$t[-1], nyse$price[-1], type = 'l')
plot(nyse$t, nyse$return, type = 'l')
```

```{r stationary-check}
grade_code()
```

### Estimation  

1.  Estimate the following autoregressive models:  
    a.  $Return_t = \beta_0 + \beta_1 Return_{t-1} + e_t$  
    b.  $Return_t = \beta_0 + \beta_1 Return_{t-1} + \beta_2 Return_{t-2} + e_t$  
    c.  $Return_t = \beta_0 + \beta_1 Return_{t-1} + \beta_2 Return_{t-2} + \beta_3 Return_{t-3} + e_t$  
2.  Present the regression results using a formatted text-formatted table with the number of observations, $R^2$, $\bar{R}^2$, and $F$ statistics reported at the bottom.  

```{r arp, exercise = TRUE}


```

```{r arp-hint}
nyse.ts <- ts(...)
ar1 <- dynlm(formula, data) 
ar2 <- dynlm(formula, data) 
ar3 <- dynlm(formula, data) 
stargazer(list, type, keep.stat)
```

```{r arp-solution}
nyse.ts <- ts(nyse)
ar1 <- dynlm(return~L(return)                        , data=nyse.ts) 
ar2 <- dynlm(return~L(return)+L(return,2)            , data=nyse.ts) 
ar3 <- dynlm(return~L(return)+L(return,2)+L(return,3), data=nyse.ts) 
stargazer(reg1, reg2, reg3, type="text", keep.stat=c("n","rsq","adj.rsq","f"))
```

```{r arp-check}
grade_code()
```

## Dynamically Complete Models in the Absence of Serial Correlation

Consistency of the static model, $y_t = \beta_0 + \beta_1 x_t + u_t$ "only" requires $E(u_t|X_t)=0$.  
Usually $u_t$ is serially correlated, but *if* we can assume that $E(u_t|X_t, y_{t-1}, X_{t-1},...) = E(u_t|X_t) = 0$, then the contemporaneous values of $X$ and $y$ contain all of the past information of themselves, and we can use the static model. 
However, this is a strong assumption.  

In general, we often encounter variables with *autocorrelation*.  
To account for this we need to include an appropriate number of *lagged* values of the dependent *and* explanatory variables in the model. This is the idea behind the *Autoregressive Distributed Lag* (ADL) model: 

$$y_t = \alpha + \rho_1 y_{t-1} + ... + \rho_p y_{t-p} + \beta_0 x_t + \beta_1 x_{t-1} + ... + \beta_p x_{t-p} + u_t$$

where $p$ is the optimal lag length that can be determined using the *Akaike Information Criterion* (AIC) or *Bayesian Information Criterion* (BIC).

## Rules of Thumb

1.  Include lags of the dependent variable
2.  Check for serial correlation in the errors (see Chapter 12)
3.  Take first (or higher-order) differences (see chapter 18)
