---
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
title: "Chapter 4 Multiple Regression Analysis - Inference"
author: "James Bang"
description: >
  This tutorial discusses tests involving multiple slope coefficients.
---

<style type="text/css">
h1{font-size: 24pt}
h2{font-size: 20pt}
h3{font-size: 18pt}
h4,h5,h6{font-size: 16pt}
body{font-size: 16pt}
</style>

<script language="JavaScript">
$(function() {
   var editor;
   $('.ace_editor').each(function( index ) {
     editor = ace.edit(this);
     editor.setFontSize("16px");
   });
})
</script>

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(car)
library(multcomp)
library(tidyverse)
library(wooldridge)
wage1 <- wooldridge::wage1
wage.lm7 <- lm(wage ~ educ + exper + I(exper^2) + tenure + profocc + clerocc + servocc, data = wage1)
wage.lm8 <- lm(wage ~ educ + exper + I(exper^2) + tenure, data = wage1)
gradethis::gradethis_setup()
knitr::opts_chunk$set(echo = FALSE)
```

## Occupation and Wages

1. Re-estimate `wage.lm7`, which from the previous tutorial regressed wage on education, experience, experience squared, job tenure, and occupation type. 
$$\begin{align}wage ={} &\beta_0 + \beta_1educ + \beta_2exper + \beta_3exper^2 + \beta_4tenure + \\ & \beta_5profocc + \beta_6clerocc + \beta_7servocc \end{align}$$
2. Summarize the result. 

```{r tTestReview, exercise = TRUE}


```

```{r tTestReview-hint}

```

```{r tTestReview-solution}
wage.lm7 <- lm(wage ~ educ + exper + I(exper^2) + tenure + profocc + clerocc + servocc, data = wage1)
summary(wage.lm7)
```

```{r tTestReview-check}
grade_this({if (!inherits(.result, c("matrix"))) {
    fail("Your class of your answer should be a `matrix` object.")}
  if (round(.result$coef[2],4) != 0.3936) { 
    fail("The coefficients on education should be about 0.39") }
  pass()
})
```

### Question

```{r pValReview, echo=FALSE}
  question("The p-Value to test whether the wages of clerical occupations differ from the baseline group (manufacturing occupations) is:",
    answer("0.0208"),
    answer("0.0824", correct = TRUE),
    answer("0.9176"),
    answer("0.3876"),
    allow_retry = TRUE
  )
```

## Testing Linear Combinations of Multiple Coefficients

Suppose we want to test whether clerical and service occupations differ *from each other*. One way to write this is: 

$$H_0: \beta_6 = \beta_7$$
$$H_1: \beta_6 \ne \beta_7$$

Another way to write this is: 

$$H_0: \beta_6 - \beta_7 = 0$$
$$H_1: \beta_6 - \beta_7 \ne 0$$

Rearranging them this way has a purpose: it places all unknown parameters on the left and numerical constants on the right. 

### Sampling distribution of $\beta_j - \beta_l$

Under $H_0$, $\beta_6 - \beta_7 = 0$

If the OLS assumptions hold, then under $H_0$,

1. $E(\hat\beta_6 - \hat\beta_7) = 0$ 
2. $Var(\hat\beta_6 - \hat\beta_7) = Var(\hat\beta_6) + Var(\hat\beta_7) - 2Cov(\hat\beta_6,\hat\beta_7)$<br>
$se_{\hat\beta_6 - \hat\beta_7} = \sqrt{Var(\hat\beta_6) + Var(\hat\beta_7) - 2Cov(\hat\beta_6,\hat\beta_7)}$

Since the parameter estimates are normally distributed, and the variances are $\chi^2$, the test statistic, 

$$ t_{\hat\beta_6-\hat\beta_7} = \frac{(\hat\beta_6 - \hat\beta_7)-0}{s_{\hat\beta_6 - \hat\beta_7}} \sim t(n-k-1) $$

### Comparing Two Occupational Groups' Wages

Use the `glht` function from the `multcomp` package (preloaded with this tutorial) to test the hypothesis that clerical occupations have the same wages as service occupations against the alternative that they differ. Pipe the test to a `summary` to give the full table of test statistics. 

Use the `lht` function from the `car` package (also preloaded). You do not need to `summary()` the results to get the output you want to see. 

```{r lincom, exercise = TRUE}



```

```{r lincom-hint}
# glht requires a model and a "linfct" option where "linfct" is a linear function of the variables in quotation marks.
# lht requires a model, a linear function of the parameters for the left-hand side of the hypothesis, and the numerical value(s) for the right hand side. 
```

```{r lincom-solution}
glht(wage.lm7, linfct = "clerocc - servocc = 0") |>
  summary()
lht(wage.lm7, "clerocc - servocc",  0)
```

```{r lincom-check}
grade_this({if (!inherits(.result, c("anova"))) {
    fail("Your class of your answer should be a `anova` object.")}
  if (round(.result$`Pr(>F)`[2],4) != 0.5574) { 
    fail("The p-value should be about 0.56") }
  pass()
})
```

Warning: "The Difference Between 'Significant' and 'Insignificant' is not Itself Statistically Significant" - Andrew Gelman

## Testing Joint Significance of Multiple Coefficients

We want to test the hypothesis that all of the occupational groups have the same wage against the alternative that *at least* one group has different wages. 

This involves (a vector of) multiple restrictions and we cannot test this hypothesis using a simple t-Test. We must use an F-test (like you might have if you have studied ANoVA). 

$$ H_0: \begin{pmatrix} \beta_{profocc} \\ \beta_{servocc} \\ \beta_{clerocc} \end{pmatrix} = \begin{pmatrix} 0\\ 0 \\ 0 \end{pmatrix} $$
$$ H_1: \begin{pmatrix} \beta_{profocc} \\ \beta_{servocc} \\ \beta_{clerocc} \end{pmatrix} \ne \begin{pmatrix} 0\\ 0 \\ 0 \end{pmatrix} $$

### Calculating the F-Statitic

There are a couple of different (but equivalent) ways to calculate the F-Statistic for the joint significance of a group of variables. They involve the same basic steps. 

1. Estimate the unrestricted model (the full model) and store the $R^2$ *or* the residual sum of squares (SSR). 
2. Estimate the restricted model (which *excludes* the variables you wish to test) and store the $R^2$ or SSR. 
3. Calculate the F statistic: 
  a. Formula using SSR: $F = \frac{(SSR_r - SSR_u)/q}{SSR_u/(n-k-1)}$
  b. Formula using $R^2$: $F = \frac{(R_u^2 - R_r^2)/q}{(1-R_u^2/(n-k-1)} $
  c. These formulas are equivalent since $R^2 = 1 - \frac{SSR}{SST}$

### Differences in Wages among All Occupational Groups

Test the joint significance of occupational choice on wages "by hand" using the $R^2$ formula:  

1. Estimate the unrestricted model and the restricted model (without occupations). 
2. Extract the R-squareds.
3. Compute the F statistic using the equation from 3(b) above. 
4. Calculate and print the p-value.

```{r fTest, exercise = TRUE}


```

```{r fTest-hint}
# Estimate the restricted Model:
# The R-squareds are an object stored in the summary() of the regression output:
# F statistic:
# p value = 1-cdf of the appropriate F distribution:
```

```{r fTest-solution}
wage.lm7 <- lm(wage ~ educ + exper + I(exper^2) + tenure + profocc + clerocc + servocc, data = wage1)
wage.lm8 <- lm(wage ~ educ + exper + I(exper^2) + tenure, data = wage1)
r2.u <- summary(wage.lm7)$r.squared
r2.r <- summary(wage.lm8)$r.squared
wage.F.occ <- ((r2.u-r2.r)/(wage.lm8$df.residual - wage.lm7$df.residual)) / ((1-r2.u)/wage.lm7$df.residual)
1 - pf(wage.F.occ, wage.lm8$df.residual -wage.lm7$df.residual, wage.lm7$df.residual)
```

```{r fTest-check}
grade_this({if(round(.result,4) != 1.152e-09) { 
    fail("The p-value should be about 1.2e-09") }
  pass()
})
```

### Warning about Independent t-Tests and a Note on the *Regression F-Statistic*

```{r independentTTest, echo=FALSE}
  question("Suppose we test these three parameters independently and reject just one of them at $\\alpha \\le 0.05$ (we do not know the actual p-value or exact t-statistic, only the result of the test for some reason). What is the probability of a type I error if we use this method to test joint significance?",
    answer("0.000125"),
    answer("0.05", message = "Careful! We cannot substitute individual t-tests for joint tests and get equivalent levels of significance! The true probability of type I error in this case is $1 - P(\text{none of the hypotheses rejected}) = 1 - 0.95^3$!"),
    answer("0.10"),
    answer("0.142625", correct = TRUE),
    allow_retry = TRUE
  )
```

The *regression F-Statistic* (the F-Statistic reported when you `summary()` a model) is simply a joint significance test where the number of restrictions is all of the independent variables. The restricted model is the unconditional mean (regression on a constant). Its formula is: 

$$ F = \frac{SSR/k}{SST/(n-k-1)} $$
